{
	"name": "FraudPrediction",
	"properties": {
		"folder": {
			"name": "SparkMLServices"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "Gsparkpool",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "54ceb84f-e55f-4242-b42a-b0382f5f7247"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/03766bec-6c31-4851-aa3c-233d9b60aeaf/resourceGroups/uiap-d-si-synapse/providers/Microsoft.Synapse/workspaces/uiap-synapse-claims-ws/bigDataPools/Gsparkpool",
				"name": "Gsparkpool",
				"type": "Spark",
				"endpoint": "https://uiap-synapse-claims-ws.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/Gsparkpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"#### Import necessary packages for Prediction using AutoML Run"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Import libraries\r\n",
					"from pyspark.sql.functions import col, pandas_udf,udf,lit\r\n",
					"from azureml.core import Workspace\r\n",
					"from azureml.core.authentication import ServicePrincipalAuthentication\r\n",
					"import azure.synapse.ml.predict as pcontext\r\n",
					"import azure.synapse.ml.predict.utils._logger as synapse_predict_logger\r\n",
					"from azureml.core.model import Model\r\n",
					"import joblib"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Define Credentials, workspace and Authentication for Prediction"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# from notebookutils.mssparkutils import azureML\r\n",
					"# ws = azureML.getWorkspace(\"AzureMLServiceClaims\")\r\n",
					"subscription_id = \"03766bec-6c31-4851-aa3c-233d9b60aeaf\"\r\n",
					"resource_group = \"uiap-d-si-synapse\"\r\n",
					"workspace_name = \"az-synapse-hack-mlworkspace\"\r\n",
					"experiment_name = \"claimfrauddetection\"\r\n",
					"\r\n",
					"ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"spark.conf.set(\"spark.synapse.ml.predict.enabled\",\"true\")"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"RETURN_TYPES = \"int\" # for ex: int, float etc. PySpark data types are supported\r\n",
					"\r\n",
					"#Define model runtime. This supports only mlflow\r\n",
					"RUNTIME = \"mlflow\"\r\n",
					"AML_MODEL_URI = \"aml://uiap-azure-ml-ws-fraud-detection-model-Best\""
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"model = pcontext.bind_model(\r\n",
					"     return_types=RETURN_TYPES, \r\n",
					"     runtime=RUNTIME, \r\n",
					"     model_alias=\"best_model\", #This alias will be used in PREDICT call to refer  this   model\r\n",
					"     model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI\r\n",
					"     aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed\r\n",
					"     ).register()"
				],
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Define credentials and input table to Read data"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"### Credentials\n",
					"driver = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
					"url = TokenLibrary.getSecret(\"ClaimsSolutionAIMLKV\", \"DSQLTargetJdbc\",\"ClaimsSolutionKV\")\n",
					"table = \"dbo.ClaimsSummary_ModelInput\""
				],
				"execution_count": 17
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Reading data using JDBC and loading as a Spark Dataframe"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"df = spark.read.format(\"jdbc\")\\\n",
					"  .option(\"driver\", driver)\\\n",
					"  .option(\"url\", url)\\\n",
					"  .option(\"dbtable\", table)\\\n",
					"  .load()\n",
					"# Converting\n",
					"pandasdf = df.toPandas()"
				],
				"execution_count": 37
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Drop Unnecessary Columns"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Drop unnecessary columns\n",
					"pandasdf.drop(['Claim_Date','ProcedureAmount','FullMemberName'], axis = 1, inplace = True)"
				],
				"execution_count": 38
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Categorize Input Data "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sparkdf = spark.createDataFrame(pandasdf)\r\n",
					"sparkdf.createOrReplaceTempView('model_input')"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"model_path = Model.get_model_path(model_name=\"uiap-azure-ml-ws-fraud-detection-model-Best\", _workspace=ws)\r\n",
					"modeljob = joblib.load(model_path + \"/model.pkl\")"
				],
				"execution_count": 69
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# columns_str= ','.join(sparkdf.columns)\r\n",
					"# predictions = spark.sql(\r\n",
					"#                   f\"\"\"\r\n",
					"#                       SELECT PREDICT('output',\r\n",
					"#                                 {columns_str}) AS predict \r\n",
					"#                       FROM model_input\r\n",
					"#                   \"\"\"\r\n",
					"#               ).show()"
				],
				"execution_count": 60
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Flag the claims using Custom Function"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"res = run(pandasdf)\n",
					"finalpdf = df.toPandas()\n",
					"finalpdf['IsMLFraudClaim'] = res\n",
					"sparkfinal = spark.createDataFrame(finalpdf)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"#### Write Predicted Output to Azure SQL Database using JDBC Connection"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def writeto_sql(dataframe, tableName, jdbcConnection):\n",
					"    dataframe.write \\\n",
					"    .format(\"jdbc\") \\\n",
					"    .mode(\"overwrite\") \\\n",
					"    .option(\"url\", jdbcConnection) \\\n",
					"    .option(\"dbtable\", tableName) \\\n",
					"    .save()\n",
					"    print(\"Data Written Successfully\")"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"jdbcconnString = dbutils.secrets.get(scope = \"ai-ml-workathon-scope\", key = \"SQLTargetJdbc\")\n",
					"writeto_sql(sparkfinal, '[dbo].ClaimsFraudOutput', jdbcconnString)"
				],
				"execution_count": null
			}
		]
	}
}